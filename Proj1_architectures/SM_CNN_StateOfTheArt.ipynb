{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import dlc_practical_prologue as prologue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Using MNIST\n",
      "** Reduce the data-set (use --full for the full thing)\n",
      "** Use 1000 train and 1000 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "/anaconda3/lib/python3.6/site-packages/torchvision/datasets/mnist.py:43: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/anaconda3/lib/python3.6/site-packages/torchvision/datasets/mnist.py:58: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/anaconda3/lib/python3.6/site-packages/torchvision/datasets/mnist.py:48: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 10])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input, train_target, test_input, test_target = \\\n",
    "prologue.load_data(one_hot_labels = True, normalize = True, flatten = False)\n",
    "                                                                        \n",
    "train_target.size()                                                                        \n",
    "                                                                        \n",
    "\n",
    "                                                                        \n",
    "                                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class CNet(nn.Module):\\n    def __init__(self, num_classes):\\n        super(CNet, self).__init__()\\n        self.conv1 = nn.Conv2d(1, 20, kernel_size=4)\\n        self.conv2 = nn.Conv2d(20, 800, kernel_size=5)\\n        self.fc1 = nn.Linear( 800*2*2,150)\\n        self.fc2 = nn.Linear(150,num_classes)\\n        \\n    def forward(self,x):\\n        x = F.torch.tanh(F.max_pool2d(self.conv1(x), kernel_size=2, stride=1))\\n        x = F.torch.tanh(F.max_pool2d(self.conv2(x), kernel_size=3, stride=1))\\n        x = F.torch.tanh(self.fc1(x.view(-1, 800*2*2)))\\n        x = F.softmax(self.fc2(x))\\n        return x'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"class CNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, kernel_size=4)\n",
    "        self.conv2 = nn.Conv2d(20, 800, kernel_size=5)\n",
    "        self.fc1 = nn.Linear( 800*2*2,150)\n",
    "        self.fc2 = nn.Linear(150,num_classes)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.torch.tanh(F.max_pool2d(self.conv1(x), kernel_size=2, stride=1))\n",
    "        x = F.torch.tanh(F.max_pool2d(self.conv2(x), kernel_size=3, stride=1))\n",
    "        x = F.torch.tanh(self.fc1(x.view(-1, 800*2*2)))\n",
    "        x = F.softmax(self.fc2(x))\n",
    "        return x\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(CNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 20, kernel_size=4)\n",
    "        self.conv2 = nn.Conv2d(20, 800, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(2*2*800,150)\n",
    "        self.fc2 = nn.Linear(150, 10)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # or use flatten\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), kernel_size = 3, stride = 3))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size = 2, stride = 2))\n",
    "        x = self.fc1(x.view(-1, 2*2*800))\n",
    "        x = F.softmax(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, mini_batch_size):\n",
    "    criterion = nn.MSELoss()\n",
    "    eta = 1e-1\n",
    "    epochs = 50\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        sum_loss = 0\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            sum_loss = sum_loss + loss.item()\n",
    "            for p in model.parameters():\n",
    "                p.data.sub_(eta*p.grad.data)\n",
    "        print(e, sum_loss)\n",
    "        \n",
    "        \n",
    "def compute_nb_errors(model, input, target, mini_batch_size):\n",
    "    for b in range (0, input.size(0), mini_batch_size):\n",
    "        output = model(input.narrow(0, b, mini_batch_size))\n",
    "        predicted_classes = output.data.max(1)\n",
    "        for k in range(mini_batch_size):\n",
    "            if target.data[b + k, predicted_classes[k]] <= 0:\n",
    "                nb_errors = nb_errors+1\n",
    "    return nb_errors\n",
    "                    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target = Variable(train_input), Variable(train_target)\n",
    "test_input, test_target = Variable(test_input), Variable(test_target)\n",
    "\n",
    "mini_batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.940513588488102\n",
      "1 1.8605083972215652\n",
      "2 1.825467862188816\n",
      "3 1.8100897073745728\n",
      "4 1.803306333720684\n",
      "5 1.8002772852778435\n",
      "6 1.798886500298977\n",
      "7 1.798209398984909\n",
      "8 1.7978424429893494\n",
      "9 1.7976096719503403\n",
      "10 1.7974344566464424\n",
      "11 1.797283574938774\n",
      "12 1.7971425876021385\n",
      "13 1.797005295753479\n",
      "14 1.7968689799308777\n",
      "15 1.796732485294342\n",
      "16 1.7965953201055527\n",
      "17 1.796457163989544\n",
      "18 1.7963179126381874\n",
      "19 1.7961773574352264\n",
      "20 1.7960354685783386\n",
      "21 1.7958920449018478\n",
      "22 1.7957469299435616\n",
      "23 1.7956000044941902\n",
      "24 1.7954511046409607\n",
      "25 1.7952999845147133\n",
      "26 1.7951464504003525\n",
      "27 1.7949902266263962\n",
      "28 1.7948310300707817\n",
      "29 1.7946685403585434\n",
      "30 1.794502355158329\n",
      "31 1.7943319901823997\n",
      "32 1.7941569313406944\n",
      "33 1.7939765229821205\n",
      "34 1.7937899604439735\n",
      "35 1.7935962826013565\n",
      "36 1.7933943271636963\n",
      "37 1.7931824773550034\n",
      "38 1.7929587587714195\n",
      "39 1.7927205264568329\n",
      "40 1.792464166879654\n",
      "41 1.7921846881508827\n",
      "42 1.7918748334050179\n",
      "43 1.7915238812565804\n",
      "44 1.79111497849226\n",
      "45 1.7906204611063004\n",
      "46 1.7899926751852036\n",
      "47 1.789145678281784\n",
      "48 1.7879219204187393\n",
      "49 1.7860608622431755\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "tensors used as indices must be long or byte tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-963b150163c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mnb_test_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_nb_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     print('test error Net {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n\u001b[1;32m      7\u001b[0m                                                       nb_test_errors, test_input.size(0)))\n",
      "\u001b[0;32m<ipython-input-94-d128a1315c5f>\u001b[0m in \u001b[0;36mcompute_nb_errors\u001b[0;34m(model, input, target, mini_batch_size)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mpredicted_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_classes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 \u001b[0mnb_errors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb_errors\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnb_errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: tensors used as indices must be long or byte tensors"
     ]
    }
   ],
   "source": [
    "#num_Classes  = 10\n",
    "for k in range(10):\n",
    "    model = CNet()\n",
    "    train_model(model, train_input, train_target, mini_batch_size)\n",
    "    nb_test_errors = compute_nb_errors(model, test_input, test_target, mini_batch_size)\n",
    "    print('test error Net {:0.2f}% {:d}/{:d}'.format((100 * nb_test_errors) / test_input.size(0),\n",
    "                                                      nb_test_errors, test_input.size(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
